# Flume / Kafka latency and throughput ingest pipeline 
cyclehire.sources=source_upstream_latency source_downstream_latency source_downstream_throughput
cyclehire.channels=channel_latency channel_buffer_latency channel_throughput
cyclehire.sinks=sink_latency sink_throughput

# Upstream Cyclehire source, optimised for low latency
cyclehire.sources.source_upstream_latency.type=com.cloudera.cyclehire.main.ingress.stream.StreamSource
cyclehire.sources.source_upstream_latency.httpUrl=http://www.tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml
cyclehire.sources.source_upstream_latency.pollMs=1000
cyclehire.sources.source_upstream_latency.pollTicks=0
cyclehire.sources.source_upstream_latency.batchSize=1
cyclehire.sources.source_upstream_latency.channels=channel_latency

# Kafka channel, optimised for low latency
cyclehire.channels.channel_latency.type=org.apache.flume.channel.kafka.KafkaChannel
cyclehire.channels.channel_latency.brokerList=$KAFKA_KAFKA_BROKER_HOSTS_AND_PORTS
cyclehire.channels.channel_latency.zookeeperConnect=$ZOOKEEPER_SERVER_HOSTS_AND_PORTS
cyclehire.channels.channel_latency.parseAsFlumeEvent=true
cyclehire.channels.channel_latency.readSmallestOffset=false
cyclehire.channels.channel_latency.capacity=10000
cyclehire.channels.channel_latency.transactionCapacity=1000
cyclehire.channels.channel_latency.topic=cyclehire_latency

# Downstream Kafka Source, optimised for low latency
cyclehire.sources.source_downstream_latency.type=org.apache.flume.source.kafka.KafkaSource
cyclehire.sources.source_downstream_latency.zookeeperConnect=$ZOOKEEPER_SERVER_HOSTS_AND_PORTS
cyclehire.sources.source_downstream_latency.groupId=cyclehire_latency
cyclehire.sources.source_downstream_latency.topic=cyclehire_latency
cyclehire.sources.source_downstream_latency.batchSize=1
cyclehire.sources.source_downstream_latency.batchDurationMillis=1000
cyclehire.sources.source_downstream_throughput.interceptors=interceptor_unwrap interceptor_stream 
cyclehire.sources.source_downstream_throughput.interceptors.interceptor_unwrap.type=com.cloudera.framework.main.common.flume.FlumeEventUnwrapInterceptor$Builder
cyclehire.sources.source_downstream_throughput.interceptors.interceptor_stream.type=com.cloudera.cyclehire.main.ingress.stream.StreamInterceptor$Builder
cyclehire.sources.source_downstream_latency.channels=channel_buffer_latency

# Downstream Memory Channel, optimised for low latency
cyclehire.channels.channel_buffer_latency.type=memory
cyclehire.channels.channel_buffer_latency.capacity=10000
cyclehire.channels.channel_buffer_latency.transactionCapacity=1000
cyclehire.channels.channel_buffer_latency.keep-alive=1
cyclehire.channels.channel_buffer_latency.byteCapacityBufferPercentage=1

# Downstream HDFS sink, optimised for low latency
cyclehire.sinks.sink_latency.type=hdfs
cyclehire.sinks.sink_latency.hdfs.path=hdfs://$HDFS_NAMENODE_HOST$ROOT_DIR_HDFS_RAW_LANDED_XML/none/%{ch_batch}_livecyclehireupdates-%{ch_host}.xml
cyclehire.sinks.sink_latency.hdfs.filePrefix=%{ch_timestamp}_livecyclehireupdates-%{ch_index}-of-%{ch_total}
cyclehire.sinks.sink_latency.hdfs.fileSuffix=.xml
cyclehire.sinks.sink_latency.hdfs.inUsePrefix=_
cyclehire.sinks.sink_latency.hdfs.rollCount=0
cyclehire.sinks.sink_latency.hdfs.rollInterval=0
cyclehire.sinks.sink_latency.hdfs.rollSize=0
cyclehire.sinks.sink_latency.hdfs.idleTimeout=1
cyclehire.sinks.sink_latency.hdfs.batchSize=1
cyclehire.sinks.sink_latency.hdfs.writeFormat=Text
cyclehire.sinks.sink_latency.hdfs.fileType=DataStream
cyclehire.sinks.sink_latency.channel=channel_buffer_latency

# Downstream Kafka Source, optimised for high throughput
cyclehire.sources.source_downstream_throughput.type=org.apache.flume.source.kafka.KafkaSource
cyclehire.sources.source_downstream_throughput.zookeeperConnect=$ZOOKEEPER_SERVER_HOSTS_AND_PORTS
cyclehire.sources.source_downstream_throughput.groupId=cyclehire_throughput
cyclehire.sources.source_downstream_throughput.topic=cyclehire_latency
cyclehire.sources.source_downstream_throughput.batchSize=10
cyclehire.sources.source_downstream_throughput.batchDurationMillis=700000
cyclehire.sources.source_downstream_throughput.interceptors=interceptor_unwrap interceptor_stream 
cyclehire.sources.source_downstream_throughput.interceptors.interceptor_unwrap.type=com.cloudera.framework.main.common.flume.FlumeEventUnwrapInterceptor$Builder
cyclehire.sources.source_downstream_throughput.interceptors.interceptor_stream.type=com.cloudera.cyclehire.main.ingress.stream.StreamInterceptor$Builder
cyclehire.sources.source_downstream_throughput.channels=channel_throughput

# Kafka channel, optimised for high throughput
cyclehire.channels.channel_throughput.type=org.apache.flume.channel.kafka.KafkaChannel
cyclehire.channels.channel_throughput.brokerList=$KAFKA_KAFKA_BROKER_HOSTS_AND_PORTS
cyclehire.channels.channel_throughput.zookeeperConnect=$ZOOKEEPER_SERVER_HOSTS_AND_PORTS
cyclehire.channels.channel_throughput.parseAsFlumeEvent=true
cyclehire.channels.channel_throughput.readSmallestOffset=true
cyclehire.channels.channel_throughput.capacity=10000
cyclehire.channels.channel_throughput.transactionCapacity=1000
cyclehire.channels.channel_throughput.topic=cyclehire_throughput

# Downstream HDFS sink, optimised for high throughput
cyclehire.sinks.sink_throughput.type=hdfs
cyclehire.sinks.sink_throughput.hdfs.path=hdfs://$HDFS_NAMENODE_HOST$ROOT_DIR_HDFS_RAW_LANDED_SEQ/none/%{ch_batch}_livecyclehireupdates-%{ch_host}.seq
cyclehire.sinks.sink_throughput.hdfs.filePrefix=%{ch_batch}_livecyclehireupdates
cyclehire.sinks.sink_throughput.hdfs.fileSuffix=.seq
cyclehire.sinks.sink_throughput.hdfs.inUsePrefix=_
cyclehire.sinks.sink_throughput.hdfs.rollCount=0
cyclehire.sinks.sink_throughput.hdfs.rollInterval=0
cyclehire.sinks.sink_throughput.hdfs.rollSize=0
cyclehire.sinks.sink_throughput.hdfs.idleTimeout=10
cyclehire.sinks.sink_throughput.hdfs.batchSize=10
cyclehire.sinks.sink_throughput.hdfs.writeFormat=Writable
cyclehire.sinks.sink_throughput.hdfs.fileType=SequenceFile
cyclehire.sinks.sink_throughput.channel=channel_throughput
